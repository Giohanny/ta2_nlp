{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Laboratorio 10\n",
    "\n",
    "\n",
    "Alumnos:\n",
    "1. Josias Carhuas Ospina - 20122631\n",
    "2. Luis Viguria Luza - 20121532\n",
    "3. Giohanny Falla Pillman - 20102205"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contenido\n",
    "El dataset es un conjunto de tweets.\n",
    "Extraido de : https://www.crowdflower.com/wp-content/uploads/2016/07/text_emotion.csv  \n",
    "Del repositorio del dataset se tiene la siguiente informaci√≥n sobre sus atributos:\n",
    "- **ID** : the numeric ID of the tweet\n",
    "- **CATEGORY** : the category of the twwet. There are 13 labels\n",
    "- **CONTENT** : the content of the tweet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>xxxPEACHESxxx</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ShansBee</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>mcsleazy</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>nic0lepaula</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Ingenue_Em</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1956969456</td>\n",
       "      <td>neutral</td>\n",
       "      <td>feinyheiny</td>\n",
       "      <td>cant fall asleep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1956969531</td>\n",
       "      <td>worry</td>\n",
       "      <td>dudeitsmanda</td>\n",
       "      <td>Choked on her retainers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1956970047</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Danied32</td>\n",
       "      <td>Ugh! I have to beat this stupid song to get to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1956970424</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Samm_xo</td>\n",
       "      <td>@BrodyJenner if u watch the hills in london u ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1956970860</td>\n",
       "      <td>surprise</td>\n",
       "      <td>okiepeanut93</td>\n",
       "      <td>Got the news</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1956971077</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Sim_34</td>\n",
       "      <td>The storm is here and the electricity is gone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1956971170</td>\n",
       "      <td>love</td>\n",
       "      <td>poppygallico</td>\n",
       "      <td>@annarosekerr agreed</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1956971206</td>\n",
       "      <td>sadness</td>\n",
       "      <td>brokenangel1982</td>\n",
       "      <td>So sleepy again and it's not even that late. I...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1956971473</td>\n",
       "      <td>worry</td>\n",
       "      <td>LCJ82</td>\n",
       "      <td>@PerezHilton lady gaga tweeted about not being...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1956971586</td>\n",
       "      <td>sadness</td>\n",
       "      <td>cleepow</td>\n",
       "      <td>How are YOU convinced that I have always wante...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1956971981</td>\n",
       "      <td>worry</td>\n",
       "      <td>andreagauster</td>\n",
       "      <td>@raaaaaaek oh too bad! I hope it gets better. ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1956972097</td>\n",
       "      <td>fun</td>\n",
       "      <td>schiz0phren1c</td>\n",
       "      <td>Wondering why I'm awake at 7am,writing a new s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1956972116</td>\n",
       "      <td>neutral</td>\n",
       "      <td>jansc</td>\n",
       "      <td>No Topic Maps talks at the Balisage Markup Con...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1956972270</td>\n",
       "      <td>worry</td>\n",
       "      <td>sweet8181</td>\n",
       "      <td>I ate Something I don't know what it is... Why...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1956972359</td>\n",
       "      <td>sadness</td>\n",
       "      <td>xamountoftruth</td>\n",
       "      <td>so tired and i think i'm definitely going to g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1956972444</td>\n",
       "      <td>worry</td>\n",
       "      <td>jomama6881</td>\n",
       "      <td>On my way home n having 2 deal w underage girl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1956972557</td>\n",
       "      <td>sadness</td>\n",
       "      <td>LilithGaea</td>\n",
       "      <td>@IsaacMascote  i'm sorry people are so rude to...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1956972884</td>\n",
       "      <td>worry</td>\n",
       "      <td>oONEPTUNEOo</td>\n",
       "      <td>Damm servers still down  i need to hit 80 befo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1956973598</td>\n",
       "      <td>sadness</td>\n",
       "      <td>username_origin</td>\n",
       "      <td>Fudge.... Just BS'd that whole paper.... So ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1956973690</td>\n",
       "      <td>worry</td>\n",
       "      <td>catchtheapple</td>\n",
       "      <td>I HATE CANCER. I HATE IT I HATE IT I HATE IT.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39970</th>\n",
       "      <td>1753904518</td>\n",
       "      <td>love</td>\n",
       "      <td>lisa24270</td>\n",
       "      <td>@Rtib happy birthday</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39971</th>\n",
       "      <td>1753904526</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>Freakonomy</td>\n",
       "      <td>@SarahSaner Hey Sarah! Hws u? Hope u remember me</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39972</th>\n",
       "      <td>1753904626</td>\n",
       "      <td>happiness</td>\n",
       "      <td>tchvinkle</td>\n",
       "      <td>@acchanosaurus good luck chan! gue kmrn bawa b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39973</th>\n",
       "      <td>1753904668</td>\n",
       "      <td>fun</td>\n",
       "      <td>Mirunnetje</td>\n",
       "      <td>good morning/midday nation!  FORMULA ONE IN ON...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39974</th>\n",
       "      <td>1753904674</td>\n",
       "      <td>love</td>\n",
       "      <td>DivasMistress</td>\n",
       "      <td>to my pretty lady @nikkiwoods HAPPY MOTHER'S D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39975</th>\n",
       "      <td>1753904682</td>\n",
       "      <td>empty</td>\n",
       "      <td>patphelan</td>\n",
       "      <td>@lexia Or even listen to Susan's green policies</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39976</th>\n",
       "      <td>1753904748</td>\n",
       "      <td>neutral</td>\n",
       "      <td>CharlotteMcFLY</td>\n",
       "      <td>right. coursework now. PROMISE</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39977</th>\n",
       "      <td>1753904799</td>\n",
       "      <td>surprise</td>\n",
       "      <td>Ocnarf10</td>\n",
       "      <td>@BuddingGenius you dont say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39978</th>\n",
       "      <td>1753904868</td>\n",
       "      <td>worry</td>\n",
       "      <td>theknickermafia</td>\n",
       "      <td>@givemestrength bloody Feds, they lost last st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39979</th>\n",
       "      <td>1753904911</td>\n",
       "      <td>surprise</td>\n",
       "      <td>fadedmoon</td>\n",
       "      <td>@prinsezha awesome. Wha'dya get her?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39980</th>\n",
       "      <td>1753904912</td>\n",
       "      <td>happiness</td>\n",
       "      <td>RyanJL</td>\n",
       "      <td>Sitting in Gatwick- going home for a week! can...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39981</th>\n",
       "      <td>1753904919</td>\n",
       "      <td>happiness</td>\n",
       "      <td>DominiqueGoh</td>\n",
       "      <td>@maynaseric good luck with your auction</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39982</th>\n",
       "      <td>1753905020</td>\n",
       "      <td>neutral</td>\n",
       "      <td>2str20lt</td>\n",
       "      <td>hey guys, if you have something to ask, just a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39983</th>\n",
       "      <td>1753905073</td>\n",
       "      <td>neutral</td>\n",
       "      <td>ABZQuine</td>\n",
       "      <td>@Astronick not really just leaving flat now, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39984</th>\n",
       "      <td>1753905113</td>\n",
       "      <td>surprise</td>\n",
       "      <td>kanjigirl</td>\n",
       "      <td>@iscreamshinki Oh that's why.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39985</th>\n",
       "      <td>1753905121</td>\n",
       "      <td>happiness</td>\n",
       "      <td>MizFitOnline</td>\n",
       "      <td>@McMedia husband is golfing &amp;amp; the Toddler ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39986</th>\n",
       "      <td>1753905153</td>\n",
       "      <td>happiness</td>\n",
       "      <td>sue_jr</td>\n",
       "      <td>going to watch boy in the striped pj's hope i ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39987</th>\n",
       "      <td>1753918809</td>\n",
       "      <td>happiness</td>\n",
       "      <td>njohari</td>\n",
       "      <td>gave the bikes a thorough wash, degrease it an...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39988</th>\n",
       "      <td>1753918818</td>\n",
       "      <td>happiness</td>\n",
       "      <td>RachellSmithles</td>\n",
       "      <td>had SUCH and AMAZING time last night, McFly we...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39989</th>\n",
       "      <td>1753918822</td>\n",
       "      <td>love</td>\n",
       "      <td>Rellz</td>\n",
       "      <td>His snoring is so annoying n it keeps me from ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39990</th>\n",
       "      <td>1753918829</td>\n",
       "      <td>neutral</td>\n",
       "      <td>kdpaine</td>\n",
       "      <td>@shonali I think the lesson of the day is not ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39991</th>\n",
       "      <td>1753918846</td>\n",
       "      <td>neutral</td>\n",
       "      <td>x0159432</td>\n",
       "      <td>@lovelylisaj can you give me the link for the ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39992</th>\n",
       "      <td>1753918881</td>\n",
       "      <td>neutral</td>\n",
       "      <td>_Alectrona_</td>\n",
       "      <td>@jasimmo Ooo showing of your French skills!! l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39993</th>\n",
       "      <td>1753918892</td>\n",
       "      <td>neutral</td>\n",
       "      <td>bushidosan</td>\n",
       "      <td>@sendsome2me haha, yeah. Twitter has many uses...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39994</th>\n",
       "      <td>1753918900</td>\n",
       "      <td>happiness</td>\n",
       "      <td>courtside101</td>\n",
       "      <td>Succesfully following Tayla!!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39995</th>\n",
       "      <td>1753918954</td>\n",
       "      <td>neutral</td>\n",
       "      <td>showMe_Heaven</td>\n",
       "      <td>@JohnLloydTaylor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39996</th>\n",
       "      <td>1753919001</td>\n",
       "      <td>love</td>\n",
       "      <td>drapeaux</td>\n",
       "      <td>Happy Mothers Day  All my love</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39997</th>\n",
       "      <td>1753919005</td>\n",
       "      <td>love</td>\n",
       "      <td>JenniRox</td>\n",
       "      <td>Happy Mother's Day to all the mommies out ther...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39998</th>\n",
       "      <td>1753919043</td>\n",
       "      <td>happiness</td>\n",
       "      <td>ipdaman1</td>\n",
       "      <td>@niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39999</th>\n",
       "      <td>1753919049</td>\n",
       "      <td>love</td>\n",
       "      <td>Alpharalpha</td>\n",
       "      <td>@mopedronin bullet train from tokyo    the gf ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>40000 rows √ó 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         tweet_id   sentiment           author  \\\n",
       "0      1956967341       empty       xoshayzers   \n",
       "1      1956967666     sadness        wannamama   \n",
       "2      1956967696     sadness        coolfunky   \n",
       "3      1956967789  enthusiasm      czareaquino   \n",
       "4      1956968416     neutral        xkilljoyx   \n",
       "5      1956968477       worry    xxxPEACHESxxx   \n",
       "6      1956968487     sadness         ShansBee   \n",
       "7      1956968636       worry         mcsleazy   \n",
       "8      1956969035     sadness      nic0lepaula   \n",
       "9      1956969172     sadness       Ingenue_Em   \n",
       "10     1956969456     neutral       feinyheiny   \n",
       "11     1956969531       worry     dudeitsmanda   \n",
       "12     1956970047     sadness         Danied32   \n",
       "13     1956970424     sadness          Samm_xo   \n",
       "14     1956970860    surprise     okiepeanut93   \n",
       "15     1956971077     sadness           Sim_34   \n",
       "16     1956971170        love     poppygallico   \n",
       "17     1956971206     sadness  brokenangel1982   \n",
       "18     1956971473       worry            LCJ82   \n",
       "19     1956971586     sadness          cleepow   \n",
       "20     1956971981       worry    andreagauster   \n",
       "21     1956972097         fun    schiz0phren1c   \n",
       "22     1956972116     neutral            jansc   \n",
       "23     1956972270       worry        sweet8181   \n",
       "24     1956972359     sadness   xamountoftruth   \n",
       "25     1956972444       worry       jomama6881   \n",
       "26     1956972557     sadness       LilithGaea   \n",
       "27     1956972884       worry      oONEPTUNEOo   \n",
       "28     1956973598     sadness  username_origin   \n",
       "29     1956973690       worry    catchtheapple   \n",
       "...           ...         ...              ...   \n",
       "39970  1753904518        love        lisa24270   \n",
       "39971  1753904526  enthusiasm       Freakonomy   \n",
       "39972  1753904626   happiness        tchvinkle   \n",
       "39973  1753904668         fun       Mirunnetje   \n",
       "39974  1753904674        love    DivasMistress   \n",
       "39975  1753904682       empty        patphelan   \n",
       "39976  1753904748     neutral   CharlotteMcFLY   \n",
       "39977  1753904799    surprise         Ocnarf10   \n",
       "39978  1753904868       worry  theknickermafia   \n",
       "39979  1753904911    surprise        fadedmoon   \n",
       "39980  1753904912   happiness           RyanJL   \n",
       "39981  1753904919   happiness     DominiqueGoh   \n",
       "39982  1753905020     neutral         2str20lt   \n",
       "39983  1753905073     neutral         ABZQuine   \n",
       "39984  1753905113    surprise        kanjigirl   \n",
       "39985  1753905121   happiness     MizFitOnline   \n",
       "39986  1753905153   happiness           sue_jr   \n",
       "39987  1753918809   happiness          njohari   \n",
       "39988  1753918818   happiness  RachellSmithles   \n",
       "39989  1753918822        love            Rellz   \n",
       "39990  1753918829     neutral          kdpaine   \n",
       "39991  1753918846     neutral         x0159432   \n",
       "39992  1753918881     neutral      _Alectrona_   \n",
       "39993  1753918892     neutral       bushidosan   \n",
       "39994  1753918900   happiness     courtside101   \n",
       "39995  1753918954     neutral    showMe_Heaven   \n",
       "39996  1753919001        love         drapeaux   \n",
       "39997  1753919005        love         JenniRox   \n",
       "39998  1753919043   happiness         ipdaman1   \n",
       "39999  1753919049        love      Alpharalpha   \n",
       "\n",
       "                                                 content  \n",
       "0      @tiffanylue i know  i was listenin to bad habi...  \n",
       "1      Layin n bed with a headache  ughhhh...waitin o...  \n",
       "2                    Funeral ceremony...gloomy friday...  \n",
       "3                   wants to hang out with friends SOON!  \n",
       "4      @dannycastillo We want to trade with someone w...  \n",
       "5      Re-pinging @ghostridah14: why didn't you go to...  \n",
       "6      I should be sleep, but im not! thinking about ...  \n",
       "7                   Hmmm. http://www.djhero.com/ is down  \n",
       "8                @charviray Charlene my love. I miss you  \n",
       "9             @kelcouch I'm sorry  at least it's Friday?  \n",
       "10                                      cant fall asleep  \n",
       "11                               Choked on her retainers  \n",
       "12     Ugh! I have to beat this stupid song to get to...  \n",
       "13     @BrodyJenner if u watch the hills in london u ...  \n",
       "14                                          Got the news  \n",
       "15         The storm is here and the electricity is gone  \n",
       "16                                  @annarosekerr agreed  \n",
       "17     So sleepy again and it's not even that late. I...  \n",
       "18     @PerezHilton lady gaga tweeted about not being...  \n",
       "19     How are YOU convinced that I have always wante...  \n",
       "20     @raaaaaaek oh too bad! I hope it gets better. ...  \n",
       "21     Wondering why I'm awake at 7am,writing a new s...  \n",
       "22     No Topic Maps talks at the Balisage Markup Con...  \n",
       "23     I ate Something I don't know what it is... Why...  \n",
       "24     so tired and i think i'm definitely going to g...  \n",
       "25     On my way home n having 2 deal w underage girl...  \n",
       "26     @IsaacMascote  i'm sorry people are so rude to...  \n",
       "27     Damm servers still down  i need to hit 80 befo...  \n",
       "28     Fudge.... Just BS'd that whole paper.... So ti...  \n",
       "29         I HATE CANCER. I HATE IT I HATE IT I HATE IT.  \n",
       "...                                                  ...  \n",
       "39970                               @Rtib happy birthday  \n",
       "39971   @SarahSaner Hey Sarah! Hws u? Hope u remember me  \n",
       "39972  @acchanosaurus good luck chan! gue kmrn bawa b...  \n",
       "39973  good morning/midday nation!  FORMULA ONE IN ON...  \n",
       "39974  to my pretty lady @nikkiwoods HAPPY MOTHER'S D...  \n",
       "39975    @lexia Or even listen to Susan's green policies  \n",
       "39976                     right. coursework now. PROMISE  \n",
       "39977                        @BuddingGenius you dont say  \n",
       "39978  @givemestrength bloody Feds, they lost last st...  \n",
       "39979               @prinsezha awesome. Wha'dya get her?  \n",
       "39980  Sitting in Gatwick- going home for a week! can...  \n",
       "39981            @maynaseric good luck with your auction  \n",
       "39982  hey guys, if you have something to ask, just a...  \n",
       "39983  @Astronick not really just leaving flat now, o...  \n",
       "39984                      @iscreamshinki Oh that's why.  \n",
       "39985  @McMedia husband is golfing &amp; the Toddler ...  \n",
       "39986  going to watch boy in the striped pj's hope i ...  \n",
       "39987  gave the bikes a thorough wash, degrease it an...  \n",
       "39988  had SUCH and AMAZING time last night, McFly we...  \n",
       "39989  His snoring is so annoying n it keeps me from ...  \n",
       "39990  @shonali I think the lesson of the day is not ...  \n",
       "39991  @lovelylisaj can you give me the link for the ...  \n",
       "39992  @jasimmo Ooo showing of your French skills!! l...  \n",
       "39993  @sendsome2me haha, yeah. Twitter has many uses...  \n",
       "39994                      Succesfully following Tayla!!  \n",
       "39995                                   @JohnLloydTaylor  \n",
       "39996                     Happy Mothers Day  All my love  \n",
       "39997  Happy Mother's Day to all the mommies out ther...  \n",
       "39998  @niariley WASSUP BEAUTIFUL!!! FOLLOW ME!!  PEE...  \n",
       "39999  @mopedronin bullet train from tokyo    the gf ...  \n",
       "\n",
       "[40000 rows x 4 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#cargamos el data set\n",
    "import pandas as pd\n",
    "ds = pd.read_csv('text_emotion.csv', sep=',')\n",
    "ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 4)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@tiffanylue i know  i was listenin to bad habit earlier and i started freakin at his part =['"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.iloc[0].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'@mopedronin bullet train from tokyo    the gf and i have been visiting japan since thursday  vacation/sightseeing    gaijin godzilla'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.iloc[39999].content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploracion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Adding Review Length\n",
    "ds['review_length'] = ds.content.apply(len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet_id</th>\n",
       "      <th>sentiment</th>\n",
       "      <th>author</th>\n",
       "      <th>content</th>\n",
       "      <th>review_length</th>\n",
       "      <th>sentiment_p1_n0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1956967341</td>\n",
       "      <td>empty</td>\n",
       "      <td>xoshayzers</td>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "      <td>92</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1956967666</td>\n",
       "      <td>sadness</td>\n",
       "      <td>wannamama</td>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "      <td>60</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1956967696</td>\n",
       "      <td>sadness</td>\n",
       "      <td>coolfunky</td>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "      <td>35</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1956967789</td>\n",
       "      <td>enthusiasm</td>\n",
       "      <td>czareaquino</td>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "      <td>36</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1956968416</td>\n",
       "      <td>neutral</td>\n",
       "      <td>xkilljoyx</td>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "      <td>86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1956968477</td>\n",
       "      <td>worry</td>\n",
       "      <td>xxxPEACHESxxx</td>\n",
       "      <td>Re-pinging @ghostridah14: why didn't you go to...</td>\n",
       "      <td>84</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1956968487</td>\n",
       "      <td>sadness</td>\n",
       "      <td>ShansBee</td>\n",
       "      <td>I should be sleep, but im not! thinking about ...</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1956968636</td>\n",
       "      <td>worry</td>\n",
       "      <td>mcsleazy</td>\n",
       "      <td>Hmmm. http://www.djhero.com/ is down</td>\n",
       "      <td>36</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1956969035</td>\n",
       "      <td>sadness</td>\n",
       "      <td>nic0lepaula</td>\n",
       "      <td>@charviray Charlene my love. I miss you</td>\n",
       "      <td>39</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1956969172</td>\n",
       "      <td>sadness</td>\n",
       "      <td>Ingenue_Em</td>\n",
       "      <td>@kelcouch I'm sorry  at least it's Friday?</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     tweet_id   sentiment         author  \\\n",
       "0  1956967341       empty     xoshayzers   \n",
       "1  1956967666     sadness      wannamama   \n",
       "2  1956967696     sadness      coolfunky   \n",
       "3  1956967789  enthusiasm    czareaquino   \n",
       "4  1956968416     neutral      xkilljoyx   \n",
       "5  1956968477       worry  xxxPEACHESxxx   \n",
       "6  1956968487     sadness       ShansBee   \n",
       "7  1956968636       worry       mcsleazy   \n",
       "8  1956969035     sadness    nic0lepaula   \n",
       "9  1956969172     sadness     Ingenue_Em   \n",
       "\n",
       "                                             content  review_length  \\\n",
       "0  @tiffanylue i know  i was listenin to bad habi...             92   \n",
       "1  Layin n bed with a headache  ughhhh...waitin o...             60   \n",
       "2                Funeral ceremony...gloomy friday...             35   \n",
       "3               wants to hang out with friends SOON!             36   \n",
       "4  @dannycastillo We want to trade with someone w...             86   \n",
       "5  Re-pinging @ghostridah14: why didn't you go to...             84   \n",
       "6  I should be sleep, but im not! thinking about ...            132   \n",
       "7               Hmmm. http://www.djhero.com/ is down             36   \n",
       "8            @charviray Charlene my love. I miss you             39   \n",
       "9         @kelcouch I'm sorry  at least it's Friday?             42   \n",
       "\n",
       "   sentiment_p1_n0  \n",
       "0                0  \n",
       "1                0  \n",
       "2                0  \n",
       "3                1  \n",
       "4                1  \n",
       "5                0  \n",
       "6                0  \n",
       "7                0  \n",
       "8                0  \n",
       "9                0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Solo los primero 10 elementos\n",
    "ds.iloc[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Vacio\t 827\n",
      "2. Tristeza\t 5165\n",
      "3. Preocupacion\t 8459\n",
      "4. Neutral\t 8638\n",
      "5. Entusiasta\t 759\n",
      "6. Amor\t\t 3842\n",
      "7. Diversion\t 1776\n",
      "8. Odio\t\t 1323\n",
      "9. Felicidad\t 5209\n",
      "10. Sorpresa\t 2187\n",
      "11. Alivio\t 1526\n",
      "12. Aburrimiento 179\n",
      "13. Enfado\t 110\n"
     ]
    }
   ],
   "source": [
    "# Cantidad de twewts por categoria\n",
    "print(\"1. Vacio\\t\", len(ds[ds.sentiment == 'empty']))\n",
    "print(\"2. Tristeza\\t\", len(ds[ds.sentiment == 'sadness'])) \n",
    "print(\"3. Preocupacion\\t\", len(ds[ds.sentiment == 'worry'])) \n",
    "print(\"4. Neutral\\t\", len(ds[ds.sentiment == 'neutral'])) \n",
    "print(\"5. Entusiasta\\t\", len(ds[ds.sentiment == 'enthusiasm'])) \n",
    "print(\"6. Amor\\t\\t\", len(ds[ds.sentiment == 'love'])) \n",
    "print(\"7. Diversion\\t\", len(ds[ds.sentiment == 'fun'])) \n",
    "print(\"8. Odio\\t\\t\", len(ds[ds.sentiment == 'hate'])) \n",
    "print(\"9. Felicidad\\t\", len(ds[ds.sentiment == 'happiness']))\n",
    "print(\"10. Sorpresa\\t\", len(ds[ds.sentiment == 'surprise']))\n",
    "print(\"11. Alivio\\t\", len(ds[ds.sentiment == 'relief']))\n",
    "print(\"12. Aburrimiento\", len(ds[ds.sentiment == 'boredom']))\n",
    "print(\"13. Enfado\\t\", len(ds[ds.sentiment == 'anger']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Dividiendo en solos dos categorias\n",
    "#Positivas = [entusiamos, amor, diversion, felicidad, neutral, alivio]\n",
    "#Negativos = [vacio, tristeza, preocupacion,odio, sorpresa, aburrimiento, enfado]\n",
    "review = []\n",
    "ds['sentiment']\n",
    "for item in ds.sentiment:\n",
    "    if(\n",
    "         item == 'enthusiasm' or \n",
    "         item == 'love' or \n",
    "         item == 'fun' or\n",
    "         item == 'neutral' or\n",
    "         item == 'happiness' or\n",
    "         item == 'relief'\n",
    "        ):\n",
    "          review.append(1)\n",
    "    if(\n",
    "         item == 'empty' or\n",
    "         item == 'sadness' or\n",
    "         item == 'worry' or\n",
    "         item == 'hate' or \n",
    "         item == 'surprise'or\n",
    "         item == 'boredom'or\n",
    "         item == 'anger'\n",
    "        ):\n",
    "          review.append(0)\n",
    "ds[\"sentiment_p1_n0\"] = review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Positivo\t 21750\n",
      "2. Negativo\t 18250\n"
     ]
    }
   ],
   "source": [
    "print(\"1. Positivo\\t\", len(ds[ds.sentiment_p1_n0 == 1]))\n",
    "print(\"2. Negativo\\t\", len(ds[ds.sentiment_p1_n0 == 0])) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Tokens total\n",
    "import numpy as np\n",
    "documents = np.asarray(ds['content'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000,)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "528675"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokens = []\n",
    "for d in documents:\n",
    "    tokens.extend(d.split())\n",
    "len(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "count_t = Counter(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "83297"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(count_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('to', 14039),\n",
       " ('I', 12635),\n",
       " ('the', 12052),\n",
       " ('a', 9352),\n",
       " ('my', 7160),\n",
       " ('and', 6750),\n",
       " ('i', 6257),\n",
       " ('you', 5535),\n",
       " ('is', 5254),\n",
       " ('for', 5146),\n",
       " ('in', 5053),\n",
       " ('of', 4419),\n",
       " ('it', 4333),\n",
       " ('on', 3828),\n",
       " ('have', 3430)]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_t.most_common(15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploraci√≥n Visual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "Missing parentheses in call to 'print' (<ipython-input-14-ff46d67ca2f3>, line 44)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-14-ff46d67ca2f3>\"\u001b[1;36m, line \u001b[1;32m44\u001b[0m\n\u001b[1;33m    print '          ',em   , '   ', sa ,'   ', en,'   ',ne,'   ',wo,'  ',su,'   ',lo,' ',fu,'   ',ht,'   ',hp,'   ',bo,'   ',re,'  ',an\u001b[0m\n\u001b[1;37m                     ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m Missing parentheses in call to 'print'\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig = plt.figure(figsize=(40, 15)) \n",
    "ax = plt.subplot2grid((2, 2), (0, 0))\n",
    "sentiment =[\"empthy\",\"sadness\",\"enthusiasm\",\"neutral\",\"worry\",'surprise','love','fun','hate','happiness','boredom','relief','anger']\n",
    "em,sa,en,ne,wo,su,lo,fu,ht,hp,bo,re,an= 0,0,0,0,0,0,0,0,0,0,0,0,0\n",
    "for i in range (len(ds)):\n",
    "    if ds['sentiment'][i] == 'empty':\n",
    "        em=em+1\n",
    "    if ds['sentiment'][i] == 'sadness':\n",
    "        sa=sa+1\n",
    "    if ds['sentiment'][i] == 'enthusiasm':\n",
    "        en=en+1\n",
    "    if ds['sentiment'][i] == 'neutral':\n",
    "        ne=ne+1\n",
    "    if ds['sentiment'][i] == 'worry':\n",
    "        wo=wo+1\n",
    "    if ds['sentiment'][i] == 'surprise':\n",
    "        su=su+1\n",
    "    if ds['sentiment'][i] == 'love':\n",
    "        lo=lo+1\n",
    "    if ds['sentiment'][i] == 'fun':\n",
    "        fu=fu+1\n",
    "    if ds['sentiment'][i] == 'hate':\n",
    "        ht=ht+1\n",
    "    if ds['sentiment'][i] == 'happiness':\n",
    "        hp=hp+1\n",
    "    if ds['sentiment'][i] == 'boredom':\n",
    "        bo=bo+1\n",
    "    if ds['sentiment'][i] == 'relief':\n",
    "        re=re+1\n",
    "    if ds['sentiment'][i] == 'anger':\n",
    "        an=an+1\n",
    "        \n",
    "datos=[em,sa,en,ne,wo,su,lo,fu,ht,hp,bo,re,an]\n",
    "xx = range(len(datos))\n",
    "\n",
    "ax.bar(xx,datos)\n",
    "ax.set_xticks(xx)\n",
    "ax.set_xticklabels(sentiment)\n",
    "plt.title(\"Clasificacion de Sentimientos\")\n",
    "\n",
    "plt.show(5)\n",
    "print '          ',em   , '   ', sa ,'   ', en,'   ',ne,'   ',wo,'  ',su,'   ',lo,' ',fu,'   ',ht,'   ',hp,'   ',bo,'   ',re,'  ',an\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-15-ce5ab5b0afb1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m \u001b[0msns\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mviolinplot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'sentiment'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'longitud'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrcParams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'figure.figsize'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m20\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'plt' is not defined"
     ]
    }
   ],
   "source": [
    "#Usando seaborn\n",
    "#Gr√°fico de longitud de los tweets por cada sentimiento\n",
    "ds['longitud'] = ds['content'].str.len()\n",
    "\n",
    "melted_df = pd.melt(ds, \n",
    "                    id_vars=[\"tweet_id\", \"sentiment\", \"longitud\"], \n",
    "                    var_name=\"content\")\n",
    "import seaborn as sns\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "sns.violinplot(x='sentiment', y='longitud', data=ds)\n",
    "plt.rcParams['figure.figsize']=(10,20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analisis sobre los textos de los tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "datos2 = ds.drop('sentiment', axis=1)\n",
    "datos2 = datos2.drop('tweet_id', axis=1)\n",
    "datos2 = datos2.drop('author', axis=1)\n",
    "datos2 = datos2.drop('review_length', axis=1)\n",
    "datos2 = datos2.drop('longitud', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>@tiffanylue i know  i was listenin to bad habi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wants to hang out with friends SOON!</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>@dannycastillo We want to trade with someone w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0  @tiffanylue i know  i was listenin to bad habi...\n",
       "1  Layin n bed with a headache  ughhhh...waitin o...\n",
       "2                Funeral ceremony...gloomy friday...\n",
       "3               wants to hang out with friends SOON!\n",
       "4  @dannycastillo We want to trade with someone w..."
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Eliminar signos de puntuacion y otros caracteres y pasar todo a min√∫sculas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import re\n",
    "pattern = r\"[,+]|[:+]|[?+]|[!+]|[-_]|[()]\"\n",
    "pattern_username = r'(\\A|\\s)@(\\w+)'\n",
    "pattern_hashtag = r'(\\A|\\s)#(\\w+)'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in datos2.iterrows():\n",
    "    cad = datos2.iloc[index]['content']\n",
    "    cad = re.sub(pattern, \"\", cad)\n",
    "    cad = re.sub(pattern_username, \"\", cad)\n",
    "    cad = re.sub(pattern_hashtag, \"\", cad)\n",
    "    cad = cad.lower()\n",
    "    datos2.set_value(index, 'content', cad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>i know  i was listenin to bad habit earlier a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layin n bed with a headache  ughhhh...waitin o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wants to hang out with friends soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>we want to trade with someone who has houston...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0   i know  i was listenin to bad habit earlier a...\n",
       "1  layin n bed with a headache  ughhhh...waitin o...\n",
       "2                funeral ceremony...gloomy friday...\n",
       "3                wants to hang out with friends soon\n",
       "4   we want to trade with someone who has houston..."
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Remover stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\hlvl\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stopWords = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stowwords removidas: 203316\n"
     ]
    }
   ],
   "source": [
    "cant_sw = 0\n",
    "for index, row in datos2.iterrows():\n",
    "    cad = datos2.iloc[index]['content']\n",
    "    lst_pals = cad.split(' ')\n",
    "    lst_temp = []\n",
    "    for item in lst_pals:\n",
    "        if item not in stopWords:\n",
    "            lst_temp.append(item)\n",
    "        else:\n",
    "            cant_sw = cant_sw + 1\n",
    "    cad = \" \".join(lst_temp)\n",
    "    datos2.set_value(index, 'content', cad)\n",
    "print(\"Stowwords removidas: \" + str(cant_sw))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know  listenin bad habit earlier started frea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layin n bed headache  ughhhh...waitin call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funeral ceremony...gloomy friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>wants hang friends soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want trade someone houston tickets one will.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0   know  listenin bad habit earlier started frea...\n",
       "1      layin n bed headache  ughhhh...waitin call...\n",
       "2                funeral ceremony...gloomy friday...\n",
       "3                            wants hang friends soon\n",
       "4       want trade someone houston tickets one will."
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicar Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem.porter import *\n",
    "ps = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in datos2.iterrows():\n",
    "    cad = datos2.iloc[index]['content']\n",
    "    lst_pals = cad.split(' ')\n",
    "    lst_temp = []\n",
    "    for item in lst_pals:\n",
    "        stemWord = ps.stem(item)\n",
    "        if stemWord not in lst_temp:\n",
    "            lst_temp.append(stemWord)\n",
    "    cad = \" \".join(lst_temp)\n",
    "    datos2.set_value(index, 'content', cad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know listenin bad habit earlier start freakin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layin n bed headach  ughhhh...waitin call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funer ceremony...gloomi friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want hang friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want trade someon houston ticket one will.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0   know listenin bad habit earlier start freakin...\n",
       "1       layin n bed headach  ughhhh...waitin call...\n",
       "2                  funer ceremony...gloomi friday...\n",
       "3                              want hang friend soon\n",
       "4         want trade someon houston ticket one will."
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicar Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for index, row in datos2.iterrows():\n",
    "    cad = datos2.iloc[index]['content']\n",
    "    lst_pals = cad.split(' ')\n",
    "    lst_temp = []\n",
    "    for item in lst_pals:\n",
    "        lemWord = lemmatizer.lemmatize(item)\n",
    "        if lemWord not in lst_temp:\n",
    "            lst_temp.append(lemWord)\n",
    "    cad = \" \".join(lst_temp)\n",
    "    datos2.set_value(index, 'content', cad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>know listenin bad habit earlier start freakin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>layin n bed headach  ughhhh...waitin call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>funer ceremony...gloomi friday...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>want hang friend soon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>want trade someon houston ticket one will.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content\n",
       "0   know listenin bad habit earlier start freakin...\n",
       "1       layin n bed headach  ughhhh...waitin call...\n",
       "2                  funer ceremony...gloomi friday...\n",
       "3                              want hang friend soon\n",
       "4         want trade someon houston ticket one will."
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datos2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  Generaci√≥n de un vector de caracteristicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 29604)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = TfidfVectorizer()\n",
    "datos_preproces = list(datos2.values.flatten())\n",
    "X = tfidf.fit_transform(datos_preproces)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# word2vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
